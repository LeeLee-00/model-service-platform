services:

  minio:
    container_name: minio
    image: minio/minio:latest
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    volumes:
      - minio-data:/data
    ports:
      - 9000:9000
      - 9001:9001
    command: server /data --console-address ":9001"
    networks:
      - nginx

  minio-init:
    container_name: minio-init
    image: minio/mc:latest
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
        until mc alias set local http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD}; do sleep 2; done &&
        until mc admin info local; do sleep 2; done &&
        mc mb local/models || true &&
        mc admin user add local ${MINIO_SVC_USER} ${MINIO_SVC_PASSWORD} || true &&
        mc admin policy create local rw-policy /policies/rw-policy.json || true &&
        mc admin policy attach local --user ${MINIO_SVC_USER} rw-policy || true
      "
    env_file:
      - .env
    volumes:
      - ./minio/rw-policy.json:/policies/rw-policy.json:ro
    networks:
      - nginx

  llm:
    runtime: nvidia
    build:
      context: ./model-service
      target: dev
    container_name: llm
    networks:
      - nginx
    depends_on:
      - minio
    environment:
      - MODEL_NAME=Qwen/Qwen1.5-0.5B-Chat
      - MODEL_TYPE=LLM
      - MINIO_ENDPOINT=${MINIO_ENDPOINT}
      - MINIO_SVC_USER=${MINIO_SVC_USER}
      - MINIO_SVC_PASSWORD=${MINIO_SVC_PASSWORD}
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      - ./model-service:/app
    ports:
      - 8000:8000

  # tinyllama:
  #   build:
  #     context: ./model-service
  #     target: dev
  #   container_name: tinyllama
  #   networks:
  #     - nginx
  #   depends_on:
  #     - minio
  #   environment:
  #     - MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0
  #     - MODEL_TYPE=LLM
  #     - MINIO_ENDPOINT=${MINIO_ENDPOINT}
  #     - MINIO_SVC_USER=${MINIO_SVC_USER}
  #     - MINIO_SVC_PASSWORD=${MINIO_SVC_PASSWORD}
  #     - HF_TOKEN=${HF_TOKEN}
  #   volumes:
  #     - ./model-service:/app
  #   ports:
  #     - 8001:8000

  # embedding:
  #   build:
  #     context: ./model-service
  #     target: dev
  #   container_name: embedding
  #   networks:
  #     - nginx
  #   depends_on:
  #     - minio
  #   environment:
  #     - MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
  #     - MODEL_TYPE=EMBEDDING
  #     - MINIO_ENDPOINT=${MINIO_ENDPOINT}
  #     - MINIO_SVC_USER=${MINIO_SVC_USER}
  #     - MINIO_SVC_PASSWORD=${MINIO_SVC_PASSWORD}
  #     - HF_TOKEN=${HF_TOKEN}
  #   volumes:
  #     - ./model-service:/app
  #   ports:
  #     - 8002:8000

  multimodal:
    runtime: nvidia
    build:
      context: ./model-service
      target: dev
    container_name: multimodal
    networks:
      - nginx
    depends_on:
      - minio
    environment:
      - MODEL_NAME=google/gemma-3-4b-it
      - MODEL_TYPE=MULTIMODAL
      - MINIO_ENDPOINT=${MINIO_ENDPOINT}
      - MINIO_SVC_USER=${MINIO_SVC_USER}
      - MINIO_SVC_PASSWORD=${MINIO_SVC_PASSWORD}
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      - ./model-service:/app
    ports:
      - 8003:8000

  # transcription:
  #   build:
  #     context: ./model-service
  #     target: dev
  #   container_name: transcription
  #   networks:
  #     - nginx
  #   depends_on:
  #     - minio
  #   environment:
  #     - MODEL_NAME=openai/whisper-small
  #     - MODEL_TYPE=TRANSCRIPTION
  #     - MINIO_ENDPOINT=${MINIO_ENDPOINT}
  #     - MINIO_SVC_USER=${MINIO_SVC_USER}
  #     - MINIO_SVC_PASSWORD=${MINIO_SVC_PASSWORD}
  #     - HF_TOKEN=${HF_TOKEN}
  #   volumes:
  #     - ./model-service:/app
  #   ports:
  #     - 8004:8000

volumes:
  minio-data:

networks:
  nginx:
    driver: bridge